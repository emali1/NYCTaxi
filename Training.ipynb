{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_total = pickle.load(open('X', 'rb'))\n",
    "Y_fare_total = pickle.load(open('Y_fare', 'rb'))\n",
    "Y_tip_total = pickle.load(open('Y_tip', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingRecordNumber = 80000\n",
    "X = X_total.as_matrix()[0:traingRecordNumber,:]\n",
    "\n",
    "\n",
    "y = Y_fare_total.tolist()[0:traingRecordNumber]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([21.57238781, 21.84944034, 21.95526326, 21.19757998, 20.83655953,\n",
       "        20.88816547, 22.41335875, 20.82805187, 20.91286528, 37.30264956,\n",
       "        21.36953074, 21.5643782 , 19.82283324, 18.48276001, 22.57965577,\n",
       "        21.52264553, 19.52096021, 18.45122129, 22.75904626, 21.82527375,\n",
       "        19.5390892 , 18.66411108, 20.19534993, 22.10143125, 21.2356357 ,\n",
       "        19.74906427, 20.55900747, 22.68916476, 21.12798172, 20.10539049,\n",
       "        19.59317172, 24.71577597, 20.97830671, 19.96041626, 20.10420519,\n",
       "        25.27109271, 20.74287784, 18.80895507, 21.44675827, 21.58840501,\n",
       "        24.62877059, 19.15925395, 20.20049727, 23.59080976, 24.24982858,\n",
       "        18.64398676, 20.04737747, 23.9717623 , 22.47842336, 19.93555915,\n",
       "        20.35693622, 24.13877958, 21.34556323, 19.48133177, 18.67775524,\n",
       "        25.62933499, 20.76485848, 19.55690855, 18.73641253, 21.92257529]),\n",
       " 'mean_score_time': array([8.02942395, 8.53136992, 8.68753654, 8.67754495, 7.491552  ,\n",
       "        8.33611697, 8.61825699, 8.67488724, 6.66633695, 7.99044925,\n",
       "        7.41695499, 7.28949624, 6.64724523, 7.85437799, 7.9780035 ,\n",
       "        8.12114698, 6.77243251, 7.51498842, 8.09311777, 7.81780374,\n",
       "        6.87336147, 7.50730598, 8.42008597, 8.13162202, 6.47803426,\n",
       "        7.59674668, 8.24623728, 8.13142502, 6.77788806, 7.75265551,\n",
       "        7.99431252, 8.42526406, 7.2942571 , 7.41515172, 7.90468007,\n",
       "        8.27829677, 7.5314157 , 7.29715991, 8.06113219, 8.60829425,\n",
       "        6.91180766, 7.07996893, 8.04138523, 8.3882575 , 6.63554066,\n",
       "        7.25914824, 8.13618934, 8.07800788, 6.40822297, 7.42948258,\n",
       "        8.26212549, 7.56485295, 6.37685955, 7.66163224, 8.18501526,\n",
       "        7.249066  , 6.68650824, 7.36115324, 7.71572417, 6.39811045]),\n",
       " 'mean_test_score': array([ 0.01763694, -0.04792334, -0.0573107 ,  0.10427311,  0.01918725,\n",
       "        -0.0478692 ,  0.15587855,  0.10040633,  0.01939392,  0.35952582,\n",
       "         0.10601381,  0.10011131, -0.05770953, -0.05773641, -0.05773644,\n",
       "        -0.0577364 , -0.05773644, -0.05773644, -0.05773644, -0.05773644,\n",
       "        -0.05773644, -0.05773644, -0.05773644, -0.05773644, -0.05746945,\n",
       "        -0.05773617, -0.05773644, -0.0577361 , -0.05773644, -0.05773644,\n",
       "        -0.05773644, -0.05773644, -0.05773644, -0.05773644, -0.05773644,\n",
       "        -0.05773644, -0.05465375, -0.05773374, -0.05773643, -0.05773306,\n",
       "        -0.05773644, -0.05773644, -0.05773643, -0.05773644, -0.05773644,\n",
       "        -0.05773644, -0.05773644, -0.05773644, -0.01508895, -0.05770953,\n",
       "        -0.05773641, -0.05770269, -0.05773644, -0.05773644, -0.05773639,\n",
       "        -0.05773644, -0.05773644, -0.05773644, -0.05773644, -0.05773644]),\n",
       " 'mean_train_score': array([ 0.0437503 , -0.03895386, -0.05457913,  0.21424794,  0.0454759 ,\n",
       "        -0.0388988 ,  0.32145853,  0.20905492,  0.04568029,  0.57353882,\n",
       "         0.25666384,  0.20847334, -0.05664446, -0.05672615, -0.05672624,\n",
       "        -0.05672615, -0.05672624, -0.05672624, -0.05672624, -0.05672624,\n",
       "        -0.05672624, -0.05672624, -0.05672624, -0.05672624, -0.0559109 ,\n",
       "        -0.05672542, -0.05672623, -0.05672535, -0.05672624, -0.05672624,\n",
       "        -0.05672623, -0.05672624, -0.05672624, -0.05672624, -0.05672624,\n",
       "        -0.05672624, -0.0483932 , -0.05671806, -0.05672623, -0.05671738,\n",
       "        -0.05672624, -0.05672624, -0.05672622, -0.05672624, -0.05672624,\n",
       "        -0.05672624, -0.05672624, -0.05672624,  0.01796112, -0.05664446,\n",
       "        -0.05672615, -0.05663769, -0.05672623, -0.05672624, -0.05672612,\n",
       "        -0.05672624, -0.05672624, -0.05672624, -0.05672624, -0.05672624]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 10, 10, 10, 100, 100, 100, 1000, 1000, 1000,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, 3, 3,\n",
       "                    3, 5, 5, 5, 7, 7, 7, 9, 9, 9, 3, 3, 3, 5, 5, 5, 7, 7,\n",
       "                    7, 9, 9, 9, 3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9, 3, 3,\n",
       "                    3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
       "              mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.01, 0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001,\n",
       "                    0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01,\n",
       "                    0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001,\n",
       "                    0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01,\n",
       "                    0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001,\n",
       "                    0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01,\n",
       "                    0.001, 0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001,\n",
       "                    0.0001, 0.01, 0.001, 0.0001, 0.01, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly', 'poly'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 7, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 7, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 7, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 9, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 9, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'degree': 9, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 7, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 7, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 7, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 9, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 9, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'degree': 9, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 7, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 7, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 7, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 9, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 9, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'degree': 9, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 3, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 5, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 7, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 7, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 7, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 9, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 9, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'degree': 9, 'gamma': 0.0001, 'kernel': 'poly'}],\n",
       " 'rank_test_score': array([ 9, 12, 14,  4,  8, 11,  2,  5,  7,  1,  3,  6, 17, 25, 35, 24, 39,\n",
       "        45, 33, 45, 45, 40, 45, 45, 15, 22, 31, 21, 37, 45, 29, 45, 45, 38,\n",
       "        45, 45, 13, 20, 28, 19, 34, 43, 27, 43, 45, 36, 45, 45, 10, 18, 26,\n",
       "        16, 30, 42, 23, 41, 45, 32, 45, 45], dtype=int32),\n",
       " 'split0_test_score': array([ 0.06274394, -0.03785578, -0.0603934 , -0.0239666 ,  0.06439198,\n",
       "        -0.03769826, -0.00089958, -0.03205059,  0.06458901,  0.18444268,\n",
       "        -0.07132126, -0.03230171, -0.06359944, -0.06367151, -0.06367158,\n",
       "        -0.06367153, -0.06367158, -0.06367158, -0.06367158, -0.06367158,\n",
       "        -0.06367158, -0.06367158, -0.06367158, -0.06367158, -0.06295129,\n",
       "        -0.06367086, -0.06367158, -0.06367111, -0.06367158, -0.06367158,\n",
       "        -0.06367158, -0.06367158, -0.06367158, -0.06367158, -0.06367158,\n",
       "        -0.06367158, -0.05653297, -0.06366435, -0.06367157, -0.06366685,\n",
       "        -0.06367158, -0.06367158, -0.06367158, -0.06367158, -0.06367158,\n",
       "        -0.06367158, -0.06367158, -0.06367158,  0.01295222, -0.06359944,\n",
       "        -0.06367151, -0.06362425, -0.06367158, -0.06367158, -0.06367154,\n",
       "        -0.06367158, -0.06367158, -0.06367158, -0.06367158, -0.06367158]),\n",
       " 'split0_train_score': array([ 0.0462867 , -0.03501111, -0.04775236,  0.21125057,  0.04847669,\n",
       "        -0.03491332,  0.31971998,  0.20511046,  0.04865954,  0.57171234,\n",
       "         0.25569037,  0.20448711, -0.04966012, -0.04972696, -0.04972703,\n",
       "        -0.04972695, -0.04972703, -0.04972703, -0.04972703, -0.04972703,\n",
       "        -0.04972703, -0.04972703, -0.04972703, -0.04972703, -0.04906018,\n",
       "        -0.04972636, -0.04972702, -0.04972625, -0.04972703, -0.04972703,\n",
       "        -0.04972702, -0.04972703, -0.04972703, -0.04972703, -0.04972703,\n",
       "        -0.04972703, -0.04325305, -0.04972033, -0.04972702, -0.04971932,\n",
       "        -0.04972703, -0.04972703, -0.04972702, -0.04972703, -0.04972703,\n",
       "        -0.04972703, -0.04972703, -0.04972703,  0.02146048, -0.04966012,\n",
       "        -0.04972696, -0.04965002, -0.04972702, -0.04972703, -0.04972692,\n",
       "        -0.04972703, -0.04972703, -0.04972702, -0.04972703, -0.04972703]),\n",
       " 'split1_test_score': array([ 0.0414867 , -0.03389133, -0.05183484,  0.16945867,  0.04352089,\n",
       "        -0.0338356 ,  0.18070798,  0.16605043,  0.04378294,  0.38617819,\n",
       "         0.14459281,  0.16562677, -0.05451152, -0.05456115, -0.0545612 ,\n",
       "        -0.05456117, -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 ,\n",
       "        -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 , -0.0540649 ,\n",
       "        -0.0545607 , -0.0545612 , -0.05456086, -0.0545612 , -0.0545612 ,\n",
       "        -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 ,\n",
       "        -0.0545612 , -0.04964362, -0.05455623, -0.0545612 , -0.05455781,\n",
       "        -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 ,\n",
       "        -0.0545612 , -0.0545612 , -0.0545612 , -0.00358999, -0.05451152,\n",
       "        -0.05456115, -0.05452731, -0.0545612 , -0.0545612 , -0.05456117,\n",
       "        -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 , -0.0545612 ]),\n",
       " 'split1_train_score': array([ 0.03150296, -0.04255995, -0.05128582,  0.21261043,  0.03318239,\n",
       "        -0.04252227,  0.32353605,  0.20815778,  0.03340736,  0.57509942,\n",
       "         0.26123817,  0.20775286, -0.0525831 , -0.05264253, -0.05264259,\n",
       "        -0.05264252, -0.05264259, -0.05264259, -0.05264259, -0.05264259,\n",
       "        -0.05264259, -0.05264259, -0.05264259, -0.05264259, -0.05204902,\n",
       "        -0.052642  , -0.05264259, -0.05264187, -0.05264259, -0.05264259,\n",
       "        -0.05264259, -0.05264259, -0.05264259, -0.05264259, -0.05264259,\n",
       "        -0.05264259, -0.04681989, -0.05263664, -0.05264259, -0.05263532,\n",
       "        -0.05264259, -0.05264259, -0.05264258, -0.05264259, -0.05264259,\n",
       "        -0.05264259, -0.05264259, -0.05264259,  0.01332117, -0.0525831 ,\n",
       "        -0.05264253, -0.05256992, -0.05264259, -0.05264259, -0.0526425 ,\n",
       "        -0.05264259, -0.05264259, -0.05264259, -0.05264259, -0.05264259]),\n",
       " 'split2_test_score': array([-0.01842171, -0.03847979, -0.03209873,  0.10373315, -0.01846417,\n",
       "        -0.03850621,  0.17652208,  0.10077422, -0.01834389,  0.39411069,\n",
       "         0.12635579,  0.10034991, -0.03206881, -0.03207475, -0.03207476,\n",
       "        -0.03207473, -0.03207476, -0.03207476, -0.03207476, -0.03207476,\n",
       "        -0.03207476, -0.03207476, -0.03207476, -0.03207476, -0.03201838,\n",
       "        -0.0320747 , -0.03207476, -0.03207451, -0.03207476, -0.03207476,\n",
       "        -0.03207476, -0.03207476, -0.03207476, -0.03207476, -0.03207476,\n",
       "        -0.03207476, -0.03182771, -0.03207416, -0.03207476, -0.03207223,\n",
       "        -0.03207476, -0.03207476, -0.03207476, -0.03207476, -0.03207476,\n",
       "        -0.03207476, -0.03207476, -0.03207476, -0.01954679, -0.03206881,\n",
       "        -0.03207475, -0.03204949, -0.03207476, -0.03207476, -0.03207472,\n",
       "        -0.03207476, -0.03207476, -0.03207476, -0.03207476, -0.03207476]),\n",
       " 'split2_train_score': array([ 0.05835094, -0.03686219, -0.05646236,  0.23619513,  0.06007838,\n",
       "        -0.03682238,  0.33838432,  0.2313128 ,  0.06031903,  0.58588632,\n",
       "         0.27436171,  0.23073059, -0.06074444, -0.06085526, -0.06085537,\n",
       "        -0.06085527, -0.06085537, -0.06085537, -0.06085537, -0.06085537,\n",
       "        -0.06085537, -0.06085537, -0.06085537, -0.06085537, -0.0597484 ,\n",
       "        -0.06085426, -0.06085537, -0.06085437, -0.06085537, -0.06085537,\n",
       "        -0.06085537, -0.06085537, -0.06085537, -0.06085537, -0.06085537,\n",
       "        -0.06085537, -0.05000593, -0.06084428, -0.06085536, -0.0608453 ,\n",
       "        -0.06085537, -0.06085537, -0.06085536, -0.06085537, -0.06085537,\n",
       "        -0.06085537, -0.06085537, -0.06085537,  0.02288495, -0.06074444,\n",
       "        -0.06085526, -0.06075465, -0.06085537, -0.06085537, -0.06085526,\n",
       "        -0.06085537, -0.06085537, -0.06085537, -0.06085537, -0.06085537]),\n",
       " 'split3_test_score': array([-0.01526118, -0.08146648, -0.08491584,  0.1678672 , -0.01269969,\n",
       "        -0.08143674,  0.26718373,  0.16685126, -0.01245238,  0.47337172,\n",
       "         0.22442789,  0.16677028, -0.08065836, -0.08063822, -0.0806382 ,\n",
       "        -0.08063817, -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 ,\n",
       "        -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 , -0.08084325,\n",
       "        -0.0806384 , -0.0806382 , -0.08063792, -0.0806382 , -0.0806382 ,\n",
       "        -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 ,\n",
       "        -0.0806382 , -0.08061071, -0.08064022, -0.0806382 , -0.08063535,\n",
       "        -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 ,\n",
       "        -0.0806382 , -0.0806382 , -0.0806382 , -0.05017123, -0.08065836,\n",
       "        -0.08063822, -0.08060971, -0.0806382 , -0.0806382 , -0.08063813,\n",
       "        -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 , -0.0806382 ]),\n",
       " 'split3_train_score': array([ 0.03886061, -0.0413822 , -0.06281597,  0.19693562,  0.04016615,\n",
       "        -0.04133725,  0.30419378,  0.19163865,  0.04033524,  0.56145721,\n",
       "         0.23536513,  0.1909228 , -0.0635902 , -0.06367986, -0.06367995,\n",
       "        -0.06367985, -0.06367995, -0.06367995, -0.06367995, -0.06367995,\n",
       "        -0.06367995, -0.06367995, -0.06367995, -0.06367995, -0.06278601,\n",
       "        -0.06367905, -0.06367995, -0.06367891, -0.06367995, -0.06367995,\n",
       "        -0.06367995, -0.06367995, -0.06367995, -0.06367995, -0.06367995,\n",
       "        -0.06367995, -0.05349391, -0.06367097, -0.06367994, -0.06366957,\n",
       "        -0.06367995, -0.06367995, -0.06367994, -0.06367995, -0.06367995,\n",
       "        -0.06367995, -0.06367995, -0.06367995,  0.01417786, -0.0635902 ,\n",
       "        -0.06367986, -0.06357618, -0.06367995, -0.06367995, -0.0636798 ,\n",
       "        -0.06367995, -0.06367995, -0.06367995, -0.06367995, -0.06367995]),\n",
       " 'std_fit_time': array([0.52242617, 0.27038308, 0.12589818, 0.33256005, 0.83339633,\n",
       "        0.88119034, 0.9157641 , 0.58846452, 1.20601964, 1.39099999,\n",
       "        0.61176249, 0.90284535, 2.04271521, 0.36260734, 0.40360064,\n",
       "        4.23713102, 2.44293222, 0.43893752, 0.70062452, 4.36740655,\n",
       "        2.38051851, 0.37972875, 2.14355888, 2.72398468, 4.34198099,\n",
       "        1.61180582, 2.47432482, 3.10288065, 4.00688257, 1.83858867,\n",
       "        2.45367643, 1.93479613, 3.45540447, 1.6007798 , 2.50413222,\n",
       "        2.4605943 , 3.11529103, 0.21842776, 3.02607743, 2.51854068,\n",
       "        3.86548158, 0.13406468, 1.80954761, 2.92685767, 3.78170857,\n",
       "        0.36862553, 1.96071404, 3.27664155, 4.55798776, 1.90949367,\n",
       "        2.39292945, 3.37392366, 4.04468612, 2.03179572, 0.27291235,\n",
       "        1.6409274 , 3.72634683, 1.60418061, 0.30014129, 3.10479537]),\n",
       " 'std_score_time': array([0.19674356, 0.13185396, 0.14507775, 0.07295942, 0.39599896,\n",
       "        0.07215852, 0.06144426, 0.07003819, 0.19792521, 0.16723691,\n",
       "        0.08110196, 0.19508802, 0.15267219, 0.16666594, 0.10299303,\n",
       "        0.10632287, 0.34610514, 0.11065144, 0.15351098, 0.37432113,\n",
       "        0.73730915, 0.45767994, 0.1591726 , 0.18296525, 0.40674671,\n",
       "        0.45979313, 0.19641204, 0.16805468, 0.29721183, 0.36481539,\n",
       "        0.29203013, 0.11912636, 0.59284351, 0.23690318, 0.39286776,\n",
       "        0.52095502, 0.94718278, 0.41018954, 0.52620524, 0.23680554,\n",
       "        0.60842476, 0.57882243, 0.40122936, 0.24182431, 0.36459003,\n",
       "        0.55203665, 0.24678056, 0.46908449, 0.25800626, 0.53375882,\n",
       "        0.37437642, 0.63872819, 0.20097762, 0.61241581, 0.28312846,\n",
       "        0.56361867, 0.27955449, 0.48890595, 0.20473535, 0.80214827]),\n",
       " 'std_test_score': array([0.03530568, 0.01944592, 0.01895505, 0.07864331, 0.03560197,\n",
       "        0.01946044, 0.0974819 , 0.08103864, 0.03562215, 0.10667879,\n",
       "        0.10882527, 0.08103851, 0.01752865, 0.01752371, 0.0175237 ,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 ,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 , 0.0175765 ,\n",
       "        0.01752375, 0.0175237 , 0.01752368, 0.0175237 , 0.0175237 ,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 ,\n",
       "        0.0175237 , 0.01748874, 0.01752419, 0.0175237 , 0.01752345,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 ,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.02328718, 0.01752865,\n",
       "        0.01752371, 0.01752117, 0.0175237 , 0.0175237 , 0.01752369,\n",
       "        0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 , 0.0175237 ]),\n",
       " 'std_train_score': array([0.00991865, 0.00311533, 0.00567545, 0.01408067, 0.01001949,\n",
       "        0.00313333, 0.01216442, 0.014275  , 0.01002949, 0.00872063,\n",
       "        0.0140421 , 0.01431621, 0.00570808, 0.00572425, 0.00572427,\n",
       "        0.00572426, 0.00572427, 0.00572427, 0.00572427, 0.00572427,\n",
       "        0.00572427, 0.00572427, 0.00572427, 0.00572427, 0.00556417,\n",
       "        0.00572411, 0.00572427, 0.00572414, 0.00572427, 0.00572427,\n",
       "        0.00572427, 0.00572427, 0.00572427, 0.00572427, 0.00572427,\n",
       "        0.00572427, 0.00379192, 0.00572265, 0.00572427, 0.00572295,\n",
       "        0.00572427, 0.00572427, 0.00572427, 0.00572427, 0.00572427,\n",
       "        0.00572427, 0.00572427, 0.00572427, 0.0042524 , 0.00570808,\n",
       "        0.00572425, 0.00571109, 0.00572427, 0.00572427, 0.00572425,\n",
       "        0.00572427, 0.00572427, 0.00572427, 0.00572427, 0.00572427])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR()\n",
    "#scores4 = cross_val_score(model, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "\n",
    "param_grid = [\n",
    " #{'C': [1, 10, 100, 1000], 'gamma': [0.01,0.001, 0.0001], 'kernel': ['linear']},\n",
    " {'C': [1, 10, 100, 1000], 'gamma': [0.01,0.001, 0.0001], 'kernel': ['rbf']},\n",
    " {'C': [1, 10, 100, 1000], 'gamma': [0.01,0.001, 0.0001], 'degree':[3,5,7,9] ,'kernel': ['poly']}\n",
    " # {'hidden_layer_sizes': [(20,20),(10,10),(20,30)]},\n",
    " ]\n",
    "\n",
    "clf = GridSearchCV(model, param_grid, cv=4,scoring='neg_mean_squared_log_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35952582028748986"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = cross_val_score(svr_rbf, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "scores3 = cross_val_score(model, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.SGDRegressor()\n",
    "scores3 = cross_val_score(model, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes=(100,30))\n",
    "scores4 = cross_val_score(model, X, y, cv=4,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51934489, 0.62366297, 0.65821017, 0.70395743])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 58.46178299\n",
      "Validation score: -1.045414\n",
      "Iteration 2, loss = 17.57554589\n",
      "Validation score: 0.120401\n",
      "Iteration 1, loss = 51.52047920\n",
      "Validation score: -1.056158\n",
      "Iteration 3, loss = 13.03822458\n",
      "Validation score: 0.222858\n",
      "Iteration 2, loss = 15.14403274\n",
      "Validation score: 0.074204\n",
      "Iteration 1, loss = 67.82242035\n",
      "Validation score: -2.803069\n",
      "Validation score: 0.281675\n",
      "Iteration 4, loss = 11.75987258\n",
      "Iteration 3, loss = 11.76018308\n",
      "Validation score: 0.147831\n",
      "Iteration 1, loss = 59.95058949\n",
      "Validation score: -2.796941\n",
      "Iteration 5, loss = 10.97953415\n",
      "Validation score: 0.318842\n",
      "Iteration 2, loss = 31.38142198\n",
      "Iteration 4, loss = 10.85769622\n",
      "Validation score: 0.007306\n",
      "Validation score: 0.192825\n",
      "Iteration 3, loss = 14.58184866\n",
      "Validation score: 0.126548\n",
      "Iteration 2, loss = 28.23306713\n",
      "Validation score: -0.009388\n",
      "Iteration 1, loss = 38.68472030\n",
      "Validation score: 0.105496\n",
      "Iteration 3, loss = 12.79266859\n",
      "Validation score: 0.075886\n",
      "Iteration 5, loss = 10.25085727\n",
      "Validation score: 0.226195\n",
      "Iteration 4, loss = 12.97499493\n",
      "Validation score: 0.204806\n",
      "Iteration 4, loss = 11.90185420\n",
      "Validation score: 0.132621\n",
      "Iteration 5, loss = 11.86466277\n",
      "Validation score: 0.255532\n",
      "Iteration 6, loss = 10.38076733\n",
      "Iteration 5, loss = 11.21446638\n",
      "Validation score: 0.185134\n",
      "Validation score: 0.352454\n",
      "Iteration 6, loss = 11.09449793\n",
      "Validation score: 0.293888\n",
      "Iteration 6, loss = 10.63557729\n",
      "Validation score: 0.230072\n",
      "Iteration 1, loss = 33.21728974\n",
      "Iteration 2, loss = 12.67979352\n",
      "Validation score: 0.066090\n",
      "Validation score: 0.277886\n",
      "Iteration 6, loss = 9.78731694\n",
      "Validation score: 0.256474\n",
      "Iteration 7, loss = 10.48277786\n",
      "Validation score: 0.326757\n",
      "Iteration 1, loss = 42.37380453\n",
      "Validation score: -0.018866\n",
      "Iteration 7, loss = 9.57559335\n",
      "Iteration 1, loss = 37.87076957\n",
      "Validation score: 0.417517\n",
      "Validation score: -0.024640\n",
      "Iteration 1, loss = 29.02693478\n",
      "Iteration 7, loss = 10.09780414\n",
      "Validation score: 0.272089\n",
      "Validation score: 0.210137\n",
      "Iteration 8, loss = 9.93011040\n",
      "Validation score: 0.358722\n",
      "Iteration 1, loss = 25.56627608\n",
      "Iteration 8, loss = 9.59521597\n",
      "Validation score: 0.313438\n",
      "Validation score: 0.135004\n",
      "Iteration 7, loss = 9.28776670\n",
      "Validation score: 0.300899\n",
      "Iteration 3, loss = 10.92964111\n",
      "Validation score: 0.339086\n",
      "Iteration 2, loss = 11.51632541\n",
      "Validation score: 0.207051\n",
      "Iteration 9, loss = 9.42794956\n",
      "Validation score: 0.387825\n",
      "Iteration 8, loss = 8.14093467\n",
      "Validation score: 0.518497\n",
      "Iteration 2, loss = 12.66453155\n",
      "Validation score: 0.108790\n",
      "Iteration 9, loss = 9.09561937\n",
      "Iteration 2, loss = 14.31263652\n",
      "Validation score: 0.353384\n",
      "Validation score: 0.180061\n",
      "Iteration 8, loss = 8.44627287\n",
      "Validation score: 0.384317\n",
      "Iteration 10, loss = 8.96894863\n",
      "Iteration 2, loss = 11.26845467\n",
      "Validation score: 0.417971\n",
      "Validation score: 0.340190\n",
      "Iteration 10, loss = 8.52374309\n",
      "Validation score: 0.399109\n",
      "Iteration 4, loss = 10.02845803\n",
      "Validation score: 0.388221\n",
      "Iteration 3, loss = 11.33148248\n",
      "Validation score: 0.178088\n",
      "Iteration 9, loss = 6.75567894\n",
      "Validation score: 0.593691\n",
      "Iteration 3, loss = 10.36031477\n",
      "Validation score: 0.269555\n",
      "Iteration 2, loss = 10.44429799\n",
      "Validation score: 0.247710\n",
      "Iteration 11, loss = 8.52416680\n",
      "Validation score: 0.447347\n",
      "Iteration 3, loss = 12.04473977\n",
      "Validation score: 0.286635\n",
      "Iteration 11, loss = 7.90192055\n",
      "Validation score: 0.444059\n",
      "Iteration 9, loss = 7.10840554\n",
      "Validation score: 0.502041\n",
      "Iteration 10, loss = 5.77729004\n",
      "Validation score: 0.646652\n",
      "Iteration 4, loss = 10.43392065\n",
      "Validation score: 0.226024\n",
      "Iteration 12, loss = 8.10789208\n",
      "Validation score: 0.474085\n",
      "Iteration 4, loss = 9.68699010\n",
      "Iteration 12, loss = 7.33282287\n",
      "Validation score: 0.483809\n",
      "Validation score: 0.321129\n",
      "Iteration 3, loss = 9.53051146\n",
      "Iteration 5, loss = 9.04615561\n",
      "Validation score: 0.424915\n",
      "Validation score: 0.456546\n",
      "Iteration 10, loss = 5.75927519\n",
      "Validation score: 0.594780\n",
      "Iteration 3, loss = 8.95366924\n",
      "Validation score: 0.376386\n",
      "Iteration 4, loss = 10.60439693\n",
      "Validation score: 0.357288\n",
      "Iteration 5, loss = 9.76786232\n",
      "Iteration 13, loss = 6.82052376\n",
      "Validation score: 0.265997\n",
      "Validation score: 0.519444\n",
      "Iteration 13, loss = 7.72393079\n",
      "Iteration 11, loss = 5.09604006\n",
      "Validation score: 0.498638\n",
      "Validation score: 0.682166\n",
      "Iteration 5, loss = 8.76385161\n",
      "Validation score: 0.409229\n",
      "Iteration 6, loss = 7.67514861\n",
      "Iteration 11, loss = 4.86665288\n",
      "Validation score: 0.553726\n",
      "Validation score: 0.650400\n",
      "Iteration 14, loss = 6.35401518\n",
      "Validation score: 0.548889\n",
      "Iteration 14, loss = 7.36254231\n",
      "Iteration 4, loss = 7.64842606\n",
      "Validation score: 0.521117\n",
      "Validation score: 0.552299\n",
      "Iteration 5, loss = 9.73389991\n",
      "Validation score: 0.403760\n",
      "Iteration 12, loss = 4.61737095\n",
      "Validation score: 0.709953\n",
      "Iteration 6, loss = 9.26855569\n",
      "Validation score: 0.302399\n",
      "Iteration 4, loss = 6.87562778\n",
      "Validation score: 0.551734\n",
      "Iteration 15, loss = 7.03880592\n",
      "Validation score: 0.541785\n",
      "Iteration 15, loss = 5.93898933\n",
      "Validation score: 0.579002\n",
      "Iteration 12, loss = 4.32363337\n",
      "Validation score: 0.679607\n",
      "Iteration 6, loss = 7.34871144\n",
      "Validation score: 0.524963\n",
      "Iteration 7, loss = 8.85020878\n",
      "Iteration 7, loss = 6.11739218\n",
      "Validation score: 0.331556\n",
      "Validation score: 0.639165\n",
      "Iteration 16, loss = 6.73517291\n",
      "Iteration 16, loss = 5.57386021\n",
      "Validation score: 0.561615\n",
      "Validation score: 0.601898\n",
      "Iteration 6, loss = 8.99970798\n",
      "Validation score: 0.451788\n",
      "Iteration 5, loss = 5.77465291\n",
      "Validation score: 0.643238\n",
      "Iteration 13, loss = 4.28073434\n",
      "Validation score: 0.729748\n",
      "Iteration 13, loss = 4.01080335\n",
      "Validation score: 0.698609\n",
      "Iteration 17, loss = 6.43695304\n",
      "Validation score: 0.580557\n",
      "Iteration 17, loss = 5.26952450\n",
      "Iteration 5, loss = 5.04885465\n",
      "Validation score: 0.620559\n",
      "Iteration 8, loss = 8.25397303\n",
      "Validation score: 0.649588\n",
      "Validation score: 0.403365\n",
      "Iteration 7, loss = 5.83881091\n",
      "Validation score: 0.617526\n",
      "Iteration 8, loss = 4.98207312\n",
      "Validation score: 0.694667\n",
      "Iteration 14, loss = 4.03264258\n",
      "Validation score: 0.745356\n",
      "Iteration 18, loss = 6.14817240\n",
      "Validation score: 0.599899\n",
      "Iteration 7, loss = 8.17822738\n",
      "Validation score: 0.503461\n",
      "Iteration 18, loss = 5.00778571\n",
      "Validation score: 0.636911\n",
      "Iteration 14, loss = 3.79321459\n",
      "Validation score: 0.710287\n",
      "Iteration 6, loss = 4.73882462\n",
      "Validation score: 0.691805\n",
      "Iteration 9, loss = 7.28234157\n",
      "Validation score: 0.479223\n",
      "Iteration 19, loss = 5.88249147\n",
      "Iteration 8, loss = 4.77572337\n",
      "Validation score: 0.616347\n",
      "Iteration 15, loss = 3.84472550\n",
      "Iteration 19, loss = 4.78303099\n",
      "Validation score: 0.672928\n",
      "Validation score: 0.755898\n",
      "Validation score: 0.652765\n",
      "Iteration 9, loss = 4.31020413\n",
      "Validation score: 0.727980\n",
      "Iteration 15, loss = 3.65287749\n",
      "Validation score: 0.719395\n",
      "Iteration 8, loss = 7.45822089\n",
      "Validation score: 0.538832\n",
      "Iteration 20, loss = 5.65038335\n",
      "Validation score: 0.632746\n",
      "Iteration 6, loss = 4.17882436\n",
      "Iteration 20, loss = 4.59660040\n",
      "Validation score: 0.665390\n",
      "Iteration 10, loss = 6.44110264\n",
      "Validation score: 0.696798\n",
      "Validation score: 0.533335\n",
      "Iteration 16, loss = 3.71533092\n",
      "Validation score: 0.764181\n",
      "Iteration 9, loss = 4.13881880\n",
      "Iteration 21, loss = 5.42254577\n",
      "Validation score: 0.647421\n",
      "Validation score: 0.704597\n",
      "Iteration 21, loss = 4.43613518\n",
      "Validation score: 0.674256\n",
      "Iteration 10, loss = 3.93099642\n",
      "Validation score: 0.746310\n",
      "Iteration 7, loss = 4.18769999\n",
      "Iteration 16, loss = 3.54554313\n",
      "Validation score: 0.715123\n",
      "Validation score: 0.727087\n",
      "Iteration 9, loss = 6.90537487\n",
      "Validation score: 0.567898\n",
      "Iteration 22, loss = 5.22348123\n",
      "Validation score: 0.661002\n",
      "Iteration 11, loss = 5.85485413\n",
      "Validation score: 0.568579\n",
      "Iteration 22, loss = 4.31769313\n",
      "Validation score: 0.682664\n",
      "Iteration 17, loss = 3.61285629\n",
      "Validation score: 0.769470\n",
      "Iteration 17, loss = 3.45709059\n",
      "Validation score: 0.733014\n",
      "Iteration 7, loss = 3.75690962\n",
      "Validation score: 0.718504\n",
      "Iteration 11, loss = 3.68603675\n",
      "Validation score: 0.757384\n",
      "Iteration 23, loss = 5.03614672\n",
      "Iteration 23, loss = 4.22081377\n",
      "Validation score: 0.673538\n",
      "Iteration 10, loss = 3.74567283\n",
      "Validation score: 0.688474\n",
      "Validation score: 0.723643\n",
      "Iteration 12, loss = 5.44604847\n",
      "Validation score: 0.594818\n",
      "Iteration 10, loss = 6.46749693\n",
      "Validation score: 0.592188\n",
      "Iteration 24, loss = 4.85750974\n",
      "Validation score: 0.685440\n",
      "Iteration 24, loss = 4.13940867\n",
      "Validation score: 0.693438\n",
      "Iteration 8, loss = 3.86111057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 3.38693619\n",
      "Validation score: 0.737293\n",
      "Validation score: 0.735561\n",
      "Iteration 18, loss = 3.54071869\n",
      "Validation score: 0.776248\n",
      "Iteration 25, loss = 4.70431341\n",
      "Iteration 12, loss = 3.53316922\n",
      "Validation score: 0.696546\n",
      "Validation score: 0.766160\n",
      "Iteration 11, loss = 6.07292329\n",
      "Validation score: 0.615573\n",
      "Iteration 25, loss = 4.06578746\n",
      "Validation score: 0.698727\n",
      "Iteration 11, loss = 3.47557509\n",
      "Iteration 13, loss = 5.14607375\n",
      "Validation score: 0.734843\n",
      "Validation score: 0.613922\n",
      "Iteration 8, loss = 3.51489055\n",
      "Validation score: 0.735987\n",
      "Iteration 19, loss = 3.32754174\n",
      "Validation score: 0.742419\n",
      "Iteration 19, loss = 3.47051819\n",
      "Iteration 26, loss = 4.56620047\n",
      "Validation score: 0.778785\n",
      "Validation score: 0.706497\n",
      "Iteration 26, loss = 4.00076872\n",
      "Validation score: 0.703189\n",
      "Iteration 9, loss = 3.62435769\n",
      "Validation score: 0.747542\n",
      "Iteration 13, loss = 3.39732762\n",
      "Validation score: 0.775957\n",
      "Iteration 27, loss = 4.42500764\n",
      "Validation score: 0.712752\n",
      "Iteration 12, loss = 3.29598490\n",
      "Iteration 27, loss = 3.94640489\n",
      "Validation score: 0.740066\n",
      "Iteration 14, loss = 4.89795996\n",
      "Validation score: 0.628897\n",
      "Iteration 20, loss = 3.28199336\n",
      "Iteration 12, loss = 5.73819623\n",
      "Validation score: 0.744196\n",
      "Validation score: 0.632790\n",
      "Validation score: 0.705108\n",
      "Iteration 20, loss = 3.41121125\n",
      "Iteration 28, loss = 4.31768487\n",
      "Validation score: 0.781811\n",
      "Validation score: 0.722012\n",
      "Iteration 28, loss = 3.89046291\n",
      "Validation score: 0.709670\n",
      "Iteration 9, loss = 3.31984619\n",
      "Validation score: 0.743879\n",
      "Iteration 14, loss = 3.28057581\n",
      "Validation score: 0.780264\n",
      "Iteration 29, loss = 4.21136804\n",
      "Validation score: 0.729840\n",
      "Iteration 15, loss = 4.68434832\n",
      "Validation score: 0.635700\n",
      "Iteration 21, loss = 3.23938423\n",
      "Validation score: 0.745259\n",
      "Iteration 10, loss = 3.44261303\n",
      "Validation score: 0.753519\n",
      "Iteration 13, loss = 3.16348195\n",
      "Iteration 21, loss = 3.35899277\n",
      "Validation score: 0.749412\n",
      "Validation score: 0.783896\n",
      "Iteration 29, loss = 3.84171458\n",
      "Iteration 13, loss = 5.48552337\n",
      "Validation score: 0.711586\n",
      "Validation score: 0.649856\n",
      "Iteration 30, loss = 4.12238000\n",
      "Validation score: 0.736156\n",
      "Iteration 22, loss = 3.19427446\n",
      "Validation score: 0.747770\n",
      "Iteration 30, loss = 3.80296195\n",
      "Iteration 16, loss = 4.52051683\n",
      "Validation score: 0.713916\n",
      "Validation score: 0.641749\n",
      "Iteration 31, loss = 4.04394142\n",
      "Iteration 15, loss = 3.20145939\n",
      "Validation score: 0.741867\n",
      "Validation score: 0.783780\n",
      "Iteration 22, loss = 3.31669924\n",
      "Validation score: 0.787765\n",
      "Iteration 14, loss = 3.06157413\n",
      "Validation score: 0.752935\n",
      "Iteration 10, loss = 3.17625103\n",
      "Validation score: 0.751999\n",
      "Iteration 31, loss = 3.76235545\n",
      "Validation score: 0.714764\n",
      "Iteration 11, loss = 3.31915097\n",
      "Iteration 14, loss = 5.29531836\n",
      "Validation score: 0.660599\n",
      "Validation score: 0.763978\n",
      "Iteration 23, loss = 3.16112634\n",
      "Validation score: 0.749677\n",
      "Iteration 17, loss = 4.39164816\n",
      "Validation score: 0.661628\n",
      "Iteration 32, loss = 3.96309933\n",
      "Validation score: 0.746833\n",
      "Iteration 32, loss = 3.73526083\n",
      "Iteration 16, loss = 3.13487241\n",
      "Validation score: 0.785551\n",
      "Iteration 23, loss = 3.27618298\n",
      "Validation score: 0.789960\n",
      "Validation score: 0.717805\n",
      "Iteration 33, loss = 3.90440095\n",
      "Validation score: 0.752079\n",
      "Iteration 24, loss = 3.12900374\n",
      "Validation score: 0.753435\n",
      "Iteration 15, loss = 2.98410951\n",
      "Validation score: 0.756787\n",
      "Iteration 18, loss = 4.25824283\n",
      "Validation score: 0.670992\n",
      "Iteration 33, loss = 3.69374148\n",
      "Validation score: 0.719961\n",
      "Iteration 15, loss = 5.12690524\n",
      "Validation score: 0.669177\n",
      "Iteration 34, loss = 3.83297936\n",
      "Validation score: 0.754834\n",
      "Iteration 11, loss = 3.07162000\n",
      "Validation score: 0.754980\n",
      "Iteration 24, loss = 3.24322580\n",
      "Validation score: 0.788928\n",
      "Iteration 12, loss = 3.20259327\n",
      "Validation score: 0.767814\n",
      "Iteration 17, loss = 3.08028993\n",
      "Validation score: 0.789250\n",
      "Iteration 34, loss = 3.65865137\n",
      "Validation score: 0.722742\n",
      "Iteration 35, loss = 3.77908358\n",
      "Validation score: 0.759298\n",
      "Iteration 19, loss = 4.15910097\n",
      "Validation score: 0.677479\n",
      "Iteration 25, loss = 3.09670952\n",
      "Validation score: 0.753394\n",
      "Iteration 16, loss = 2.92374333\n",
      "Validation score: 0.756424\n",
      "Iteration 16, loss = 4.99295868\n",
      "Validation score: 0.678515\n",
      "Iteration 35, loss = 3.62149543\n",
      "Validation score: 0.723767\n",
      "Iteration 36, loss = 3.72927804\n",
      "Validation score: 0.761010\n",
      "Iteration 20, loss = 4.06081515\n",
      "Validation score: 0.683490\n",
      "Iteration 25, loss = 3.21375588\n",
      "Validation score: 0.794252\n",
      "Iteration 26, loss = 3.07182890\n",
      "Validation score: 0.754926\n",
      "Iteration 18, loss = 3.03576868\n",
      "Validation score: 0.790807\n",
      "Iteration 36, loss = 3.60000077\n",
      "Validation score: 0.725761\n",
      "Iteration 37, loss = 3.68934311\n",
      "Validation score: 0.764132\n",
      "Iteration 17, loss = 2.84952832\n",
      "Validation score: 0.753621\n",
      "Iteration 12, loss = 2.97061695\n",
      "Validation score: 0.759692\n",
      "Iteration 13, loss = 3.12171410\n",
      "Validation score: 0.772320\n",
      "Iteration 17, loss = 4.86629633\n",
      "Validation score: 0.686415\n",
      "Iteration 27, loss = 3.05209102\n",
      "Iteration 21, loss = 3.95984597\n",
      "Validation score: 0.756318\n",
      "Iteration 38, loss = 3.64544782\n",
      "Validation score: 0.692382\n",
      "Validation score: 0.766868\n",
      "Iteration 26, loss = 3.18679426\n",
      "Iteration 37, loss = 3.56556354\n",
      "Validation score: 0.794461\n",
      "Validation score: 0.728071\n",
      "Iteration 19, loss = 2.99188896\n",
      "Validation score: 0.791304\n",
      "Iteration 18, loss = 2.80688678\n",
      "Iteration 38, loss = 3.53951229\n",
      "Iteration 39, loss = 3.61345546\n",
      "Validation score: 0.760692\n",
      "Validation score: 0.730710\n",
      "Validation score: 0.767939\n",
      "Iteration 28, loss = 3.02414368\n",
      "Validation score: 0.758023\n",
      "Iteration 22, loss = 3.85983711\n",
      "Validation score: 0.698809\n",
      "Iteration 27, loss = 3.16825750\n",
      "Validation score: 0.796434\n",
      "Iteration 18, loss = 4.74749761\n",
      "Validation score: 0.694367\n",
      "Iteration 13, loss = 2.90114071\n",
      "Validation score: 0.760504\n",
      "Iteration 40, loss = 3.57723014\n",
      "Iteration 39, loss = 3.52390001\n",
      "Validation score: 0.769901\n",
      "Validation score: 0.729317\n",
      "Iteration 14, loss = 3.03901097\n",
      "Validation score: 0.775687\n",
      "Iteration 20, loss = 2.97798827\n",
      "Validation score: 0.789252\n",
      "Iteration 29, loss = 3.00710152\n",
      "Validation score: 0.757471\n",
      "Iteration 19, loss = 2.75504457\n",
      "Iteration 41, loss = 3.55096704\n",
      "Validation score: 0.762379\n",
      "Validation score: 0.771820\n",
      "Iteration 40, loss = 3.48921349\n",
      "Validation score: 0.729765\n",
      "Iteration 23, loss = 3.78972645\n",
      "Validation score: 0.701448\n",
      "Iteration 28, loss = 3.16230757\n",
      "Validation score: 0.795649\n",
      "Iteration 19, loss = 4.63480743\n",
      "Validation score: 0.700369\n",
      "Iteration 42, loss = 3.51715281\n",
      "Validation score: 0.772538\n",
      "Iteration 41, loss = 3.46072169\n",
      "Iteration 21, loss = 2.93383475\n",
      "Validation score: 0.733084\n",
      "Validation score: 0.795146\n",
      "Iteration 30, loss = 2.98728229\n",
      "Validation score: 0.760554\n",
      "Iteration 14, loss = 2.84775270\n",
      "Validation score: 0.763693\n",
      "Iteration 29, loss = 3.12911133\n",
      "Validation score: 0.798135\n",
      "Iteration 20, loss = 2.72147047\n",
      "Validation score: 0.762513\n",
      "Iteration 15, loss = 2.97991475\n",
      "Validation score: 0.776469\n",
      "Iteration 43, loss = 3.49716531\n",
      "Validation score: 0.775437\n",
      "Iteration 24, loss = 3.72790827\n",
      "Validation score: 0.705577\n",
      "Iteration 20, loss = 4.52137510\n",
      "Iteration 42, loss = 3.44139972\n",
      "Validation score: 0.706767\n",
      "Validation score: 0.735359\n",
      "Iteration 31, loss = 2.96339929\n",
      "Validation score: 0.760282\n",
      "Iteration 44, loss = 3.47316721\n",
      "Validation score: 0.777697\n",
      "Iteration 22, loss = 2.92074737\n",
      "Iteration 43, loss = 3.41603639\n",
      "Validation score: 0.792386\n",
      "Validation score: 0.735566\n",
      "Iteration 30, loss = 3.10888569\n",
      "Validation score: 0.798048\n",
      "Iteration 25, loss = 3.67480069\n",
      "Validation score: 0.709876\n",
      "Iteration 21, loss = 2.69225504\n",
      "Validation score: 0.760864\n",
      "Iteration 45, loss = 3.44987238\n",
      "Validation score: 0.777817\n",
      "Iteration 15, loss = 2.81072305\n",
      "Iteration 21, loss = 4.42161072\n",
      "Validation score: 0.765153\n",
      "Validation score: 0.713393\n",
      "Iteration 44, loss = 3.40175602\n",
      "Iteration 32, loss = 2.94962854\n",
      "Validation score: 0.759954\n",
      "Validation score: 0.737092\n",
      "Iteration 16, loss = 2.92159457\n",
      "Validation score: 0.779063\n",
      "Iteration 46, loss = 3.42782042\n",
      "Validation score: 0.778096\n",
      "Iteration 31, loss = 3.09149988\n",
      "Validation score: 0.798930\n",
      "Iteration 23, loss = 2.88776447\n",
      "Validation score: 0.796372\n",
      "Iteration 45, loss = 3.37588925\n",
      "Validation score: 0.737913\n",
      "Iteration 26, loss = 3.61952564\n",
      "Validation score: 0.712411\n",
      "Iteration 33, loss = 2.93116862\n",
      "Validation score: 0.762559\n",
      "Iteration 22, loss = 2.65461644\n",
      "Validation score: 0.763396\n",
      "Iteration 47, loss = 3.40992262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.780019\n",
      "Iteration 22, loss = 4.31568679\n",
      "Validation score: 0.722450\n",
      "Iteration 46, loss = 3.36030798\n",
      "Iteration 32, loss = 3.08631774\n",
      "Validation score: 0.738863\n",
      "Validation score: 0.799123\n",
      "Iteration 48, loss = 3.38761034\n",
      "Validation score: 0.779761\n",
      "Iteration 16, loss = 2.75405978\n",
      "Validation score: 0.766694\n",
      "Iteration 24, loss = 2.86055579\n",
      "Iteration 27, loss = 3.57086167\n",
      "Validation score: 0.797914\n",
      "Validation score: 0.714690\n",
      "Iteration 34, loss = 2.92025663\n",
      "Iteration 17, loss = 2.88683444\n",
      "Validation score: 0.762416\n",
      "Validation score: 0.779358\n",
      "Iteration 47, loss = 3.34632111\n",
      "Validation score: 0.739025\n",
      "Iteration 49, loss = 3.37315928\n",
      "Validation score: 0.779674\n",
      "Iteration 33, loss = 3.06648412\n",
      "Validation score: 0.799982\n",
      "Iteration 23, loss = 2.63495819\n",
      "Validation score: 0.764837\n",
      "Iteration 23, loss = 4.23230524\n",
      "Validation score: 0.726018\n",
      "Iteration 48, loss = 3.32544816\n",
      "Validation score: 0.741858\n",
      "Iteration 28, loss = 3.52713734\n",
      "Validation score: 0.712556\n",
      "Iteration 35, loss = 2.90727511\n",
      "Validation score: 0.761311\n",
      "Iteration 50, loss = 3.34948488\n",
      "Validation score: 0.782275\n",
      "Iteration 25, loss = 2.83311540\n",
      "Iteration 34, loss = 3.05855045\n",
      "Validation score: 0.799097\n",
      "Validation score: 0.798589\n",
      "Iteration 49, loss = 3.29924335\n",
      "Iteration 17, loss = 2.71196255\n",
      "Validation score: 0.765936\n",
      "Validation score: 0.743608\n",
      "Iteration 18, loss = 2.85357737\n",
      "Iteration 51, loss = 3.33778320\n",
      "Validation score: 0.783442\n",
      "Validation score: 0.780405\n",
      "Iteration 24, loss = 4.15179088\n",
      "Validation score: 0.732034\n",
      "Iteration 36, loss = 2.89217426\n",
      "Validation score: 0.763629\n",
      "Iteration 24, loss = 2.60758397\n",
      "Iteration 29, loss = 3.47911175\n",
      "Validation score: 0.763761\n",
      "Validation score: 0.721026\n",
      "Iteration 50, loss = 3.27946290\n",
      "Validation score: 0.742739\n",
      "Iteration 35, loss = 3.05644832\n",
      "Validation score: 0.800000\n",
      "Iteration 52, loss = 3.31419223\n",
      "Validation score: 0.782764\n",
      "Iteration 26, loss = 2.81357640\n",
      "Validation score: 0.799587\n",
      "Iteration 51, loss = 3.26978501\n",
      "Validation score: 0.743716\n",
      "Iteration 37, loss = 2.87592407\n",
      "Validation score: 0.764153\n",
      "Iteration 30, loss = 3.44811209\n",
      "Iteration 53, loss = 3.30323663\n",
      "Validation score: 0.782551\n",
      "Iteration 25, loss = 4.07251102\n",
      "Validation score: 0.734949\n",
      "Validation score: 0.725059\n",
      "Iteration 18, loss = 2.68173481\n",
      "Validation score: 0.766679\n",
      "Iteration 36, loss = 3.03586843\n",
      "Validation score: 0.799117\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 2.82016466\n",
      "Validation score: 0.783225\n",
      "Iteration 25, loss = 2.58279620\n",
      "Validation score: 0.762151\n",
      "Iteration 52, loss = 3.25463650\n",
      "Validation score: 0.745562\n",
      "Iteration 54, loss = 3.28733809\n",
      "Validation score: 0.785401\n",
      "Iteration 27, loss = 2.80421085\n",
      "Validation score: 0.799518\n",
      "Iteration 53, loss = 3.24201222\n",
      "Iteration 38, loss = 2.86409003\n",
      "Validation score: 0.745814\n",
      "Validation score: 0.764104\n",
      "Iteration 31, loss = 3.40366151\n",
      "Validation score: 0.727770\n",
      "Iteration 26, loss = 3.98547871\n",
      "Iteration 55, loss = 3.27156135\n",
      "Validation score: 0.736446\n",
      "Validation score: 0.787124\n",
      "Iteration 26, loss = 2.56841011\n",
      "Validation score: 0.762100\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 2.64241305\n",
      "Iteration 54, loss = 3.23301566\n",
      "Validation score: 0.746830\n",
      "Validation score: 0.767745\n",
      "Iteration 56, loss = 3.25740052\n",
      "Validation score: 0.786662\n",
      "Iteration 28, loss = 2.79051606\n",
      "Validation score: 0.798794\n",
      "Iteration 20, loss = 2.78549394\n",
      "Iteration 39, loss = 2.85422421\n",
      "Validation score: 0.775291\n",
      "Validation score: 0.763368\n",
      "Iteration 32, loss = 3.37281882\n",
      "Validation score: 0.724185\n",
      "Iteration 55, loss = 3.21655344\n",
      "Validation score: 0.747601\n",
      "Iteration 27, loss = 3.90951787\n",
      "Validation score: 0.742021\n",
      "Iteration 57, loss = 3.24868864\n",
      "Validation score: 0.788074\n",
      "Iteration 56, loss = 3.20603832\n",
      "Validation score: 0.748472\n",
      "Iteration 33, loss = 3.34675834\n",
      "Validation score: 0.730500\n",
      "Iteration 40, loss = 2.84191649\n",
      "Validation score: 0.762642\n",
      "Iteration 29, loss = 2.77993758\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Validation score: 0.798631\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 58, loss = 3.23260115\n",
      "Validation score: 0.787556\n",
      "Iteration 57, loss = 3.19014073\n",
      "Validation score: 0.749560\n",
      "Iteration 21, loss = 2.77607714\n",
      "Validation score: 0.780149\n",
      "Iteration 20, loss = 2.62069616\n",
      "Iteration 28, loss = 3.84911317\n",
      "Validation score: 0.767897\n",
      "Validation score: 0.745501\n",
      "Iteration 59, loss = 3.22176859\n",
      "Validation score: 0.788952\n",
      "Iteration 58, loss = 3.17561940\n",
      "Iteration 34, loss = 3.32394404\n",
      "Validation score: 0.748005\n",
      "Validation score: 0.730342\n",
      "Iteration 60, loss = 3.20428624\n",
      "Validation score: 0.788951\n",
      "Iteration 29, loss = 3.78792505\n",
      "Validation score: 0.746679\n",
      "Iteration 59, loss = 3.17181958\n",
      "Validation score: 0.750116\n",
      "Iteration 22, loss = 2.73699220\n",
      "Validation score: 0.781504\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 60, loss = 3.15827694\n",
      "Validation score: 0.749897\n",
      "Iteration 35, loss = 3.28892365\n",
      "Validation score: 0.732622\n",
      "Iteration 61, loss = 3.20658106\n",
      "Validation score: 0.788111\n",
      "Iteration 21, loss = 2.59254431\n",
      "Validation score: 0.764247\n",
      "Iteration 61, loss = 3.14590993\n",
      "Validation score: 0.750551\n",
      "Iteration 62, loss = 3.17920868\n",
      "Validation score: 0.789778\n",
      "Iteration 30, loss = 3.72799982\n",
      "Validation score: 0.750835\n",
      "Iteration 62, loss = 3.14519688\n",
      "Iteration 36, loss = 3.27089854\n",
      "Validation score: 0.751859\n",
      "Validation score: 0.733439\n",
      "Iteration 63, loss = 3.17348719\n",
      "Validation score: 0.791279\n",
      "Iteration 63, loss = 3.12640200\n",
      "Validation score: 0.753239\n",
      "Iteration 64, loss = 3.15661406\n",
      "Validation score: 0.790686\n",
      "Iteration 31, loss = 3.66971959\n",
      "Validation score: 0.756289\n",
      "Iteration 22, loss = 2.57486779\n",
      "Validation score: 0.770408\n",
      "Iteration 37, loss = 3.24570695\n",
      "Validation score: 0.735751\n",
      "Iteration 64, loss = 3.11667067\n",
      "Validation score: 0.752994\n",
      "Iteration 65, loss = 3.14984144\n",
      "Validation score: 0.791520\n",
      "Iteration 66, loss = 3.15382254\n",
      "Validation score: 0.791929\n",
      "Iteration 32, loss = 3.61235496\n",
      "Validation score: 0.754331\n",
      "Iteration 65, loss = 3.10626143\n",
      "Validation score: 0.752508\n",
      "Iteration 67, loss = 3.13422801\n",
      "Validation score: 0.793956\n",
      "Iteration 38, loss = 3.22779716\n",
      "Validation score: 0.734232\n",
      "Iteration 23, loss = 2.55353183\n",
      "Validation score: 0.763983\n",
      "Iteration 66, loss = 3.09805864\n",
      "Validation score: 0.753904\n",
      "Iteration 68, loss = 3.12685037\n",
      "Validation score: 0.794977\n",
      "Iteration 39, loss = 3.19826387\n",
      "Validation score: 0.739394\n",
      "Iteration 33, loss = 3.56941081\n",
      "Iteration 67, loss = 3.08277469\n",
      "Validation score: 0.758352\n",
      "Validation score: 0.754304\n",
      "Iteration 69, loss = 3.11707859\n",
      "Validation score: 0.794497\n",
      "Iteration 24, loss = 2.53757117\n",
      "Iteration 68, loss = 3.08222105\n",
      "Validation score: 0.766456\n",
      "Validation score: 0.755200\n",
      "Iteration 40, loss = 3.18697650\n",
      "Validation score: 0.738494\n",
      "Iteration 70, loss = 3.10453328\n",
      "Validation score: 0.795126\n",
      "Iteration 34, loss = 3.51755352\n",
      "Validation score: 0.761750\n",
      "Iteration 69, loss = 3.07034922\n",
      "Validation score: 0.756196\n",
      "Iteration 71, loss = 3.10033012\n",
      "Validation score: 0.796976\n",
      "Iteration 70, loss = 3.06251580\n",
      "Iteration 41, loss = 3.17581954\n",
      "Validation score: 0.757852\n",
      "Validation score: 0.741168\n",
      "Iteration 72, loss = 3.09611902\n",
      "Validation score: 0.797906\n",
      "Iteration 25, loss = 2.51282517\n",
      "Validation score: 0.769534\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 35, loss = 3.48175379\n",
      "Validation score: 0.761854\n",
      "Iteration 73, loss = 3.08926090\n",
      "Validation score: 0.795221\n",
      "Iteration 71, loss = 3.05636205\n",
      "Validation score: 0.756668\n",
      "Iteration 72, loss = 3.04579460\n",
      "Validation score: 0.757271\n",
      "Iteration 42, loss = 3.15818939\n",
      "Validation score: 0.739412\n",
      "Iteration 36, loss = 3.44043717\n",
      "Iteration 74, loss = 3.07721264\n",
      "Validation score: 0.766371\n",
      "Validation score: 0.797523\n",
      "Iteration 73, loss = 3.03589522\n",
      "Validation score: 0.757272\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 43, loss = 3.14623644\n",
      "Validation score: 0.741133\n",
      "Iteration 75, loss = 3.07004079\n",
      "Validation score: 0.795344\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37, loss = 3.40386335\n",
      "Validation score: 0.767351\n",
      "Iteration 44, loss = 3.13001275\n",
      "Validation score: 0.742073\n",
      "Iteration 38, loss = 3.36711008\n",
      "Validation score: 0.771656\n",
      "Iteration 45, loss = 3.11365871\n",
      "Validation score: 0.740845\n",
      "Iteration 39, loss = 3.33312187\n",
      "Validation score: 0.773973\n",
      "Iteration 46, loss = 3.10271767\n",
      "Validation score: 0.743738\n",
      "Iteration 40, loss = 3.31105533\n",
      "Validation score: 0.771558\n",
      "Iteration 47, loss = 3.09123862\n",
      "Validation score: 0.744978\n",
      "Iteration 41, loss = 3.28184357\n",
      "Validation score: 0.776425\n",
      "Iteration 48, loss = 3.07131972\n",
      "Validation score: 0.747964\n",
      "Iteration 42, loss = 3.24957271\n",
      "Validation score: 0.778164\n",
      "Iteration 49, loss = 3.05910083\n",
      "Validation score: 0.746775\n",
      "Iteration 43, loss = 3.22483670\n",
      "Validation score: 0.777851\n",
      "Iteration 50, loss = 3.05999839\n",
      "Validation score: 0.747206\n",
      "Iteration 44, loss = 3.21487331\n",
      "Validation score: 0.777112\n",
      "Iteration 51, loss = 3.03481911\n",
      "Validation score: 0.749333\n",
      "Iteration 45, loss = 3.18967275\n",
      "Validation score: 0.778408\n",
      "Iteration 52, loss = 3.02932307\n",
      "Validation score: 0.748247\n",
      "Iteration 46, loss = 3.17782180\n",
      "Validation score: 0.781262\n",
      "Iteration 53, loss = 3.04013018\n",
      "Validation score: 0.744910\n",
      "Iteration 47, loss = 3.16106415\n",
      "Validation score: 0.783745\n",
      "Iteration 54, loss = 3.01846181\n",
      "Validation score: 0.750897\n",
      "Iteration 48, loss = 3.13690478\n",
      "Validation score: 0.780170\n",
      "Iteration 55, loss = 3.00371716\n",
      "Validation score: 0.752197\n",
      "Iteration 49, loss = 3.13095475\n",
      "Validation score: 0.781587\n",
      "Iteration 56, loss = 2.98910421\n",
      "Validation score: 0.751219\n",
      "Iteration 50, loss = 3.12264922\n",
      "Validation score: 0.782688\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 57, loss = 3.00308286\n",
      "Validation score: 0.751209\n",
      "Iteration 58, loss = 2.98122481\n",
      "Validation score: 0.755567\n",
      "Iteration 59, loss = 2.98216250\n",
      "Validation score: 0.746934\n",
      "Iteration 60, loss = 2.97106288\n",
      "Validation score: 0.754427\n",
      "Iteration 61, loss = 2.96335240\n",
      "Validation score: 0.754843\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 24.00707265\n",
      "Validation score: 0.234929\n",
      "Iteration 2, loss = 10.45022782\n",
      "Validation score: 0.356509\n",
      "Iteration 3, loss = 8.47839613\n",
      "Validation score: 0.543332\n",
      "Iteration 4, loss = 5.78060619\n",
      "Validation score: 0.691704\n",
      "Iteration 5, loss = 4.29994928\n",
      "Validation score: 0.744836\n",
      "Iteration 6, loss = 3.71492028\n",
      "Validation score: 0.769582\n",
      "Iteration 7, loss = 3.42752164\n",
      "Validation score: 0.780396\n",
      "Iteration 8, loss = 3.25609454\n",
      "Validation score: 0.786802\n",
      "Iteration 9, loss = 3.14056869\n",
      "Validation score: 0.793400\n",
      "Iteration 10, loss = 3.05708088\n",
      "Validation score: 0.796620\n",
      "Iteration 11, loss = 3.00327256\n",
      "Validation score: 0.797833\n",
      "Iteration 12, loss = 2.94981941\n",
      "Validation score: 0.800408\n",
      "Iteration 13, loss = 2.91726183\n",
      "Validation score: 0.802317\n",
      "Iteration 14, loss = 2.88797804\n",
      "Validation score: 0.801693\n",
      "Iteration 15, loss = 2.86082506\n",
      "Validation score: 0.802843\n",
      "Iteration 16, loss = 2.83590726\n",
      "Validation score: 0.802355\n",
      "Iteration 17, loss = 2.82170194\n",
      "Validation score: 0.804330\n",
      "Iteration 18, loss = 2.80554437\n",
      "Validation score: 0.802661\n",
      "Iteration 19, loss = 2.78961110\n",
      "Validation score: 0.804184\n",
      "Iteration 20, loss = 2.77846269\n",
      "Validation score: 0.801591\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([44.26575148, 52.14788306, 44.28620005, 48.02043295, 52.93529093]),\n",
       " 'mean_score_time': array([0.16057551, 0.03941262, 0.25239801, 0.17281103, 0.08647251]),\n",
       " 'mean_test_score': array([0.75621768, 0.74305245, 0.76520967, 0.76083137, 0.7351524 ]),\n",
       " 'mean_train_score': array([0.80363425, 0.79265058, 0.8219059 , 0.82441406, 0.79382765]),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[(30, 20), (10, 10, 10), (100, 30), (100, 100),\n",
       "                    (10, 10, 100)],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'hidden_layer_sizes': (30, 20)},\n",
       "  {'hidden_layer_sizes': (10, 10, 10)},\n",
       "  {'hidden_layer_sizes': (100, 30)},\n",
       "  {'hidden_layer_sizes': (100, 100)},\n",
       "  {'hidden_layer_sizes': (10, 10, 100)}],\n",
       " 'rank_test_score': array([3, 4, 1, 2, 5], dtype=int32),\n",
       " 'split0_test_score': array([0.75753604, 0.757298  , 0.76397403, 0.75537299, 0.74122646]),\n",
       " 'split0_train_score': array([0.81541108, 0.81032837, 0.83136334, 0.83154246, 0.80538989]),\n",
       " 'split1_test_score': array([0.75489931, 0.7288069 , 0.76644532, 0.76628974, 0.72907833]),\n",
       " 'split1_train_score': array([0.79185742, 0.7749728 , 0.81244846, 0.81728566, 0.78226541]),\n",
       " 'std_fit_time': array([1.64174354, 0.17812812, 1.04390192, 1.68835688, 0.03203094]),\n",
       " 'std_score_time': array([0.03274238, 0.00643241, 0.05854297, 0.029423  , 0.00012159]),\n",
       " 'std_test_score': array([0.00131836, 0.01424555, 0.00123565, 0.00545837, 0.00607406]),\n",
       " 'std_train_score': array([0.01177683, 0.01767779, 0.00945744, 0.0071284 , 0.01156224])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPRegressor(early_stopping=True,alpha=0.1)\n",
    "#scores4 = cross_val_score(model, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "\n",
    "param_grid = [\n",
    " {'hidden_layer_sizes': [(30,20),(10,10,10),(100,30),(100,100),(10,10,100)]},\n",
    " ]\n",
    "\n",
    "clf2 = GridSearchCV(model, param_grid, cv=2,scoring='neg_mean_squared_log_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "clf2.fit(X,y)\n",
    "\n",
    "clf2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (100, 30)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7652096725988836"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "scores5 = cross_val_score(model, X, y, cv=2,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41034614, 0.36752934])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: -0.06042, std: 0.00964, params: {'n_estimators': 40},\n",
       " mean: -0.06044, std: 0.00974, params: {'n_estimators': 50},\n",
       " mean: -0.06032, std: 0.00970, params: {'n_estimators': 70},\n",
       " mean: -0.06024, std: 0.00976, params: {'n_estimators': 90},\n",
       " mean: -0.06019, std: 0.00972, params: {'n_estimators': 100}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "#scores4 = cross_val_score(model, X2, y, cv=4,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "\n",
    "param_grid = [\n",
    " {'n_estimators': [40,50,70,90,100]},\n",
    " ]\n",
    "\n",
    "clf3 = GridSearchCV(model, param_grid, cv=2,scoring='neg_mean_squared_log_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "clf3.fit(X,y)\n",
    "\n",
    "clf3.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06019398714100908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.32991, std: 0.06035, params: {'n_estimators': 1},\n",
       " mean: 0.42838, std: 0.06358, params: {'n_estimators': 2},\n",
       " mean: 0.45766, std: 0.05827, params: {'n_estimators': 3},\n",
       " mean: 0.50714, std: 0.05840, params: {'n_estimators': 5},\n",
       " mean: 0.52913, std: 0.05613, params: {'n_estimators': 8},\n",
       " mean: 0.53066, std: 0.06186, params: {'n_estimators': 13},\n",
       " mean: 0.53539, std: 0.05560, params: {'n_estimators': 21}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.51329, std: 0.05373, params: {'n_estimators': 10},\n",
       " mean: 0.52514, std: 0.05248, params: {'n_estimators': 20},\n",
       " mean: 0.52391, std: 0.05316, params: {'n_estimators': 21},\n",
       " mean: 0.52801, std: 0.05558, params: {'n_estimators': 25},\n",
       " mean: 0.52800, std: 0.05455, params: {'n_estimators': 30},\n",
       " mean: 0.53099, std: 0.05468, params: {'n_estimators': 40},\n",
       " mean: 0.53247, std: 0.05679, params: {'n_estimators': 50}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5,000 training record\n",
    "clf3.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.64380, std: 0.00536, params: {'n_estimators': 10},\n",
       " mean: 0.65528, std: 0.00533, params: {'n_estimators': 20},\n",
       " mean: 0.65537, std: 0.00596, params: {'n_estimators': 21},\n",
       " mean: 0.65716, std: 0.00737, params: {'n_estimators': 25},\n",
       " mean: 0.65722, std: 0.00688, params: {'n_estimators': 30},\n",
       " mean: 0.65992, std: 0.00756, params: {'n_estimators': 40},\n",
       " mean: 0.66120, std: 0.00861, params: {'n_estimators': 50}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10,000 training records \n",
    "clf3.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ma_emali/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([37.10210252, 45.66356099, 47.67764902, 57.14844954, 71.60533106,\n",
       "        71.45125592, 83.15435445]),\n",
       " 'mean_score_time': array([0.37322199, 0.38710749, 0.31660593, 0.37683642, 0.45772552,\n",
       "        0.60212946, 0.65768898]),\n",
       " 'mean_test_score': array([0.73886527, 0.73957106, 0.74058233, 0.74108138, 0.74130634,\n",
       "        0.74132676, 0.74168197]),\n",
       " 'mean_train_score': array([0.89268877, 0.8933535 , 0.89412065, 0.89439995, 0.89481608,\n",
       "        0.89496105, 0.89503387]),\n",
       " 'param_n_estimators': masked_array(data=[25, 30, 40, 50, 70, 90, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 25},\n",
       "  {'n_estimators': 30},\n",
       "  {'n_estimators': 40},\n",
       "  {'n_estimators': 50},\n",
       "  {'n_estimators': 70},\n",
       "  {'n_estimators': 90},\n",
       "  {'n_estimators': 100}],\n",
       " 'rank_test_score': array([7, 6, 5, 4, 3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.72764111, 0.72866445, 0.72939577, 0.72969061, 0.72951868,\n",
       "        0.72909367, 0.72915275]),\n",
       " 'split0_train_score': array([0.89643591, 0.89681937, 0.89762571, 0.89788366, 0.8981148 ,\n",
       "        0.89826617, 0.89831043]),\n",
       " 'split1_test_score': array([0.75008943, 0.75047767, 0.75176889, 0.75247215, 0.75309401,\n",
       "        0.75355985, 0.7542112 ]),\n",
       " 'split1_train_score': array([0.88894162, 0.88988762, 0.89061558, 0.89091623, 0.89151735,\n",
       "        0.89165593, 0.89175731]),\n",
       " 'std_fit_time': array([1.36893749, 0.48919094, 9.45271111, 1.96589267, 3.25296199,\n",
       "        6.00357306, 0.02491057]),\n",
       " 'std_score_time': array([0.00079596, 0.03479946, 0.01641905, 0.02515161, 0.01008344,\n",
       "        0.02053356, 0.02216303]),\n",
       " 'std_test_score': array([0.01122416, 0.01090661, 0.01118656, 0.01139077, 0.01178767,\n",
       "        0.01223309, 0.01252923]),\n",
       " 'std_train_score': array([0.00374715, 0.00346588, 0.00350507, 0.00348371, 0.00329873,\n",
       "        0.00330512, 0.00327656])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20,000 \n",
    "clf3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([100.59290159, 130.75815189, 144.47923303, 176.01671815,\n",
       "        214.50431168]),\n",
       " 'mean_score_time': array([0.69378245, 0.76790452, 1.02121747, 1.24964488, 1.33111739]),\n",
       " 'mean_test_score': array([0.7309409 , 0.73172492, 0.73209486, 0.73301072, 0.73289327]),\n",
       " 'mean_train_score': array([0.88230468, 0.88258803, 0.88287593, 0.88305084, 0.88313213]),\n",
       " 'param_n_estimators': masked_array(data=[40, 50, 70, 90, 100],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 40},\n",
       "  {'n_estimators': 50},\n",
       "  {'n_estimators': 70},\n",
       "  {'n_estimators': 90},\n",
       "  {'n_estimators': 100}],\n",
       " 'rank_test_score': array([5, 4, 3, 1, 2], dtype=int32),\n",
       " 'split0_test_score': array([0.68429371, 0.68555115, 0.68588649, 0.6875556 , 0.68732029]),\n",
       " 'split0_train_score': array([0.88407442, 0.8844071 , 0.88462326, 0.88482495, 0.88491263]),\n",
       " 'split1_test_score': array([0.77758809, 0.77789869, 0.77830323, 0.77846584, 0.77846626]),\n",
       " 'split1_train_score': array([0.88053495, 0.88076895, 0.8811286 , 0.88127673, 0.88135163]),\n",
       " 'std_fit_time': array([21.11780655, 12.97001302,  8.99684191,  7.05865502,  3.60856354]),\n",
       " 'std_score_time': array([0.02946341, 0.0881865 , 0.04772842, 0.05574501, 0.0270524 ]),\n",
       " 'std_test_score': array([0.04664719, 0.04617377, 0.04620837, 0.04545512, 0.04557298]),\n",
       " 'std_train_score': array([0.00176973, 0.00181908, 0.00174733, 0.00177411, 0.0017805 ])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#40,000 \n",
    "clf3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
